# LandscapeDiffusion
Diffusion models are able to produce novel images quickly, and they are blurring the boundaries between human and AI-generated art.
For this project, we are interested specifically in their ability to generate landscape photos and novel landscapes.
We will use a subset of a Kaggle landscape image dataset to train our model. 
Moreover, we will inspect the effect of changing hyperparameters related to noise schedules and activation functions. 
Finally, we will inspect the differences in training the model unconditionally (without the dataset labels) and conditionally.
The results can be found in "report.pdf"

Acknowledgement:
The following projects served as crucial guides in our exploration.
https://github.com/dome272/Diffusion-Models-pytorch
https://github.com/tcapelle/Diffusion-Models-pytorch
